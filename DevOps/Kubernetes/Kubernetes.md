Назад к: [[DevOps]]

---
## Содержание:

^086721

[[Kubernetes#^14a421|Общая информация]]
[[Kubernetes#^9f3498|Ключевые моменты]]
[[Kubernetes#^071f26|Основные понятия]]
[[Kubernetes#^fbb34a|Как работает]]
[[Kubernetes#^8f97e4|Возможные вопросы]]

---
## Общая информация:
Kubernetes — это система оркестрации контейнеров с открытым исходным кодом, созданная для автоматизации развёртывания, масштабирования и управления контейнерными приложениями. Она организует контейнеры в поды, которые распределяются по кластерам и могут масштабироваться в зависимости от нагрузки. Kubernetes предоставляет такие возможности, как автоматическое восстановление сервисов, балансировка нагрузки, управление конфигурацией и секретами, что упрощает развертывание и эксплуатацию облачных приложений.

[[Kubernetes#^086721|К содержанию]]

---
## Ключевые моменты:
- **Оркестрация контейнеров** – автоматизирует развертывание, управление и масштабирование контейнеров.
- **Масштабирование и самовосстановление** – автоматически масштабирует поды и восстанавливает упавшие контейнеры.
- **Балансировка нагрузки** – распределяет трафик между подами для равномерной загрузки.
- **Управление конфигурацией и секретами** – позволяет безопасно управлять чувствительными данными.
- **Разделение по пространствам имен** – поддерживает многопользовательские среды через namespaces.
- **Обновление и откат** – обеспечивает безостановочное обновление приложений и откат на предыдущую версию.
- **Интеграция с различными инфраструктурами** – работает как в облачных, так и в локальных средах.

[[Kubernetes#^086721|К содержанию]]

---
## Основные понятия:
- **Кластер** – группа узлов(нод) (виртуальных или физических машин), объединенных для работы под управлением Kubernetes. ^69a669
- **Узел (Node)** – отдельная машина в кластере, где запускаются поды. Может быть виртуальной или физической. ^e11fb4
- **Под (Pod)** – минимальная единица в Kubernetes, представляющая собой один или несколько контейнеров, которые работают вместе и разделяют сеть и хранилище. ^b38bf8
- **Secret** – объект для хранения чувствительных данных (например, паролей, ключей), которые могут быть использованы подами.
- **ConfigMap** – объект для хранения неконфиденциальных данных конфигурации, которые могут быть использованы подами.
- **Kubectl** – командная утилита для управления Kubernetes-кластером. С ее помощью можно выполнять команды, такие как развертывание приложений, мониторинг ресурсов и изменение конфигураций. ^82576b
- **Dashboard** – веб-интерфейс для управления и мониторинга кластера. Dashboard предоставляет графический интерфейс для выполнения основных операций в кластере и отслеживания состояния подов, служб и других ресурсов.
- **Служба (Service)** – абстракция, обеспечивающая постоянный IP-адрес и DNS-имя для доступа к набору подов.
- **Контроллер (Controller)** – компонент, поддерживающий желаемое состояние ресурсов (например, ReplicationController или Deployment). ^e4e618
- **Deployment** – ресурс для управления развертыванием и обновлением подов с поддержкой масштабирования и откатов.
- **ReplicaSet** – объект, который обеспечивает заданное количество копий (реплик) подов.
- **Namespace** – пространство имен, позволяющее разделять ресурсы кластера между различными пользователями или окружениями.
- **Ingress** – ресурс, позволяющий управлять внешним доступом к сервисам кластера (например, HTTP/HTTPS).
- **Volume** – абстракция для работы с хранилищем, предоставляющая подам доступ к постоянным данным.
- **Kubelet** – агент, запускающийся на каждом узле кластера. Он отвечает за поддержание заданного состояния подов (запускает контейнеры, проверяет их статус) в соответствии с инструкциями от API Server. ^cbc3b1
- **Kube-proxy** – сетевой прокси, работающий на каждом узле кластера. Он управляет сетевыми правилами для обеспечения связи между подами и сервисами, выполняя маршрутизацию трафика к соответствующим подам. ^f74d39
- **Container Runtime** – программное обеспечение, ответственное за запуск контейнеров. Kubernetes поддерживает различные контейнерные рантаймы, такие как Docker, containerd и CRI-O.
- **API Server** – основной компонент, обеспечивающий взаимодействие между различными компонентами Kubernetes и внешними клиентами. Он обрабатывает запросы через REST API, управляет состоянием кластера и хранит данные в etcd. ^9e0c07
- **Scheduler** – компонент, отвечающий за назначение подов на узлы в кластере. Он выбирает оптимальный узел для запуска каждого пода, исходя из доступных ресурсов и политик. ^b35c72
- **Kube Controller Manager** – набор контроллеров, управляющих различными аспектами кластера (например, контроллер репликации, контроллер узлов). Эти контроллеры обеспечивают поддержание состояния кластера в соответствии с желаемой конфигурацией. ^9d3bfb
- **Cloud Controller Manager** – контроллер, который взаимодействует с облачными провайдерами для управления ресурсами, такими как узлы, балансировщики нагрузки и маршруты, специфичными для облачной инфраструктуры. ^42c5df
- **etcd** – распределенное хранилище данных, используемое для хранения всех данных состояния Kubernetes-кластера. Оно гарантирует консистентность данных, необходимых для управления кластером.

[[Kubernetes#^086721|К содержанию]]

---
## Как работает:
1. **Мастер-[[Kubernetes#^e11fb4|узел]]** (мастер-нода) управляет [[Kubernetes#^69a669|кластером]] и включает компоненты [[Kubernetes#^9e0c07|API Server]], [[Kubernetes#^b35c72|Scheduler]] и [[Kubernetes#^9d3bfb|Controller Manager]], которые отслеживают состояние [[Kubernetes#^69a669|кластера]] и распределяют [[Kubernetes#^b38bf8|поды]] на [[Kubernetes#^e11fb4|узлы]].
2. **Рабочие [[Kubernetes#^e11fb4|узлы]]** запускают [[Kubernetes#^b38bf8|поды]] с контейнерами. На каждом узле работает агент [[Kubernetes#^cbc3b1|Kubelet]], который взаимодействует с мастер-узлом, и [[Kubernetes#^f74d39|Kube-proxy]] для маршрутизации сетевого трафика.
3. Пользователь или система подают команды через [[Kubernetes#^82576b|kubectl]] или [[Kubernetes#^9e0c07|API Server]], описывая желаемое состояние (например, сколько [[Kubernetes#^b38bf8|подов]] запустить, какие контейнеры использовать).
4. **[[Kubernetes#^b35c72|Scheduler]]** выбирает [[Kubernetes#^e11fb4|узлы]] для запуска [[Kubernetes#^b38bf8|подов]], а [[Kubernetes#^e4e618|контроллеры]] поддерживают нужное количество [[Kubernetes#^b38bf8|подов]] и их состояние.
5. Kubernetes автоматически масштабирует, восстанавливает и балансирует нагрузку на контейнеры, обеспечивая их стабильную и отказоустойчивую работу.

[[Kubernetes#^086721|К содержанию]]

---
## Возможные вопросы:

^885a61

[[Kubernetes#^e35ac8|Что такое контейнеры? Чем они отличаются от виртуальных машин?]]
[[Kubernetes#^a22bd8|В чем разница stateful и stateless?]]
[[Kubernetes#^d7e87b|Что такое Kubernetes и зачем он нужен?]]
[[Kubernetes#^d7e87b|Как Kubernetes соотносится с Docker?]]
[[Kubernetes#^f598a3|Назовите главные компоненты архитектуры Kubernetes]]
[[Kubernetes#^1efec6|Что такое под (pod)?]]
Для чего при старте PODа создаётся контейнер с процессом pause?
Каким образом мы можем управлять размещением PODов на конкретных нодах кластера k8s?
Что такое Pod Disruption Budget (PDB)?
Что такое POD eviction?
Каким образом мы можем вывести ноду из работы для обслуживания?
Что такое priority classes?
Что такое Kubernetes probes?
Какие существуют хорошие практики для создания проб?
[[Kubernetes#^9d023b|Что такое пространство имен (namespaces)? Почему не стоит использовать одно namespace для всех приложений?]]
[[Kubernetes#^d96056|Какую функцию выполняет ReplicaSet?]]
[[Kubernetes#^3ff4f8|Что такое Deployment?]]
[[Kubernetes#^32615f|За что отвечает StatefulSet?]]
[[Kubernetes#^883294|Какая роль у контроллера DaemonSet?]]
[[Kubernetes#^ccbb49|Как в Kubernetes устроена работа с хранилищами?]]
[[Kubernetes#^42da4e|Как в Kubernetes сделать приложение доступным извне по сети интернет?]]
[[Kubernetes#^603e32|Что такое ingress и зачем он нужен?]]
Если нам всё равно нужно описывать Kubernetes service для публикации ingress, то зачем нам ingress?
Допустим, у нас postgresql в кластере k8s, и разработчики просят к ней доступ. Каким образом мы можем решить этот вопрос?
[[Kubernetes#^320f06|Расскажите, как вы будете запускать приложение в Kubernetes, если из инструментов у вас только kubectl?]]
[[Kubernetes#^d7e87b|Приложение перестало работать — как понять, что случилось?]]

[[Kubernetes#^086721|К содержанию]]

---
 **Что такое контейнеры? Чем они отличаются от виртуальных машин?**
	Контейнеры — это сущность, которая содержит в себе все зависимости (системные библиотеки, сторонние пакеты кода и прочее), необходимые для запуска приложения. Контейнеры позволяют быстро запускать приложения без оглядки на окружающую среду.  
	И контейнеры, и виртуальные машины — это технологии виртуализации ресурсов.  
	Основное различие контейнеров и виртуальных машин заключается в том, что виртуальные машины виртуализируют весь компьютер/сервер вплоть до аппаратного уровня. На виртуальную машину можно установить любую гостевую ОС, и она может быть отличной от ОС компьютера/сервера.  
	Контейнеры же виртуализируют только то, что выше уровня операционной системы. То есть контейнеры делят друг с другом ядро операционной системы, которая установлена на сервере. Благодаря этому контейнеры занимают меньше ресурсов и быстрее запускаются. В то же время контейнеры не так изолированы друг от друга, как виртуальные машины. ^e35ac8
[[Kubernetes#^885a61|К списку вопросов]]
**В чем разница stateful и stateless?**
	Если говорить применительно к приложениям, то Stateful-приложение — это то, которое сохраняет данные при работе как состояние внутри себя. Примером могут быть сессии пользователей, которые хранятся на сервере. Ответ на запрос пользователя зависит от состояния сессии.  
	Такие приложения сложнее масштабировать горизонтально: чтобы развернуть несколько экземпляров, нужно переносить состояния на новые машины и синхронизировать их.  
	Stateless — любой запрос к приложению уникален, а его ответ не зависит от какого-либо состояния приложения. Stateless-приложения легко масштабируются горизонтально, упрощают автоматизированное тестирование, так как нет состояния, которое нужно воспроизводить. ^a22bd8
[[Kubernetes#^885a61|К списку вопросов]]
**Что такое Kubernetes и зачем он нужен?**
	Kubernetes — это open-source-платформа для автоматизированного запуска, масштабирования и управления контейнеризированными приложениями.  
	С помощью Kubernetes можно:  
	- запускать приложение в контейнере на нескольких серверах/площадках. Если ваши приложения работают на 2–3 серверах, то можно обойтись и без Kubernetes, но если их десятки и сотни, то дальнейшее масштабирование, управление и апдейт будет сложнее без дополнительного инструмента оркестрации. Как раз таким и является Kubernetes;
	- автоматически развертывать, апдейтить, откатывать назад обновления, управлять состоянием контейнеров;
	- управлять нагрузкой и оперативно масштабироваться в большую или меньшую сторону.
	Если хотите блеснуть эрудицией, можно сказать, что Kubernetes — это детище Google, в k8s 8 означает 8 букв в слове kubernetes, а само название переводится с греческого как «кормчий, рулевой».
[[Kubernetes#^885a61|К списку вопросов]]
**Как Kubernetes соотносится с Docker?**
	Docker — это один из общепринятых стандартов контейнеризации. С его помощью мы упаковываем приложения в контейнеры, автоматизируем их запуск и развертывание, управление их жизненным циклом. Docker позволяет запускать один контейнер на одном хосте. А что если нужно запустить несколько контейнеров на разных хостах и как-то ими управлять?  
	Вот здесь приходит на помощь Kubernetes, который помогает настраивать сетевую связность Docker-контейнеров, запущенных на разных хостах, и оркестровать их.  
	То есть Docker — контейнер, Kubernetes — платформа для управления контейнерами, или оркестратор контейнеров.
[[Kubernetes#^885a61|К списку вопросов]]
**Назовите главные компоненты архитектуры Kubernetes.**
	**Master-ноды (master node, control plane)** координируют все активности кластера: распределяют и резервируют ресурсы, управляют состоянием контейнеров, масштабируют, раскатывают обновления. 
	Мастер-ноды состоят из следующих компонентов:  
	- **kube-apiserver** — это точка входа в панель управления master-ноды. Он отвечает за взаимодействие между master- и worker-нодами, отслеживает состояние worker-узлов и оповещает master о важных изменениях;
	- **kube-scheduler** отвечает за распределение нагрузки на рабочие узлы, постоянно отслеживает, сколько ресурсов сейчас доступно и сколько из них задействовано под нагрузку на каждом узле. Он решает, на каком узле запускать новый Pod;
	- **Controller Manager** отвечает за работу контроллеров: Deployment, ReplicaSet, StatefulSets, DaemonSet, Jobs, CronJob;
	- **etcd** хранит информацию о настройках и состоянии кластера, его метаданные. Представляет собой распределенную базу данных в формате ключ-значение.
	**Nodes (workers)** — рабочие узлы в кластере. На них запускаются поды с контейнерами.  
	На каждой worker-ноде Kubernetes работают:  
	- **kubelet** — процесс, который запускает, удаляет, обновляет поды с контейнерами;
	- **kube-proxy** — конфигурирует правила сети на рабочих узлах.
	![[Pasted image 20241104212318.png]]
[[Kubernetes#^885a61|К списку вопросов]] ^f598a3
**Что такое под (pod)?**
	**Под** — это самая маленькая сущность в Kubernetes, в которой запускаются контейнеры. Контейнеров внутри пода может быть несколько.  
	Помимо контейнеров, у каждого пода есть:  
	— уникальный IP-адрес, который позволяет подам общаться друг с другом;  
	— хранилище PV (по необходимости);  
	— данные по конфигурации, которые определяют, как контейнер должен запускаться.
	![[Pasted image 20241104212601.png]]
[[Kubernetes#^885a61|К списку вопросов]] ^1efec6
**Для чего при старте PODа создаётся контейнер с процессом pause?**
	Для PODа создаются как минимум два контейнера. Первый контейнер с pause служит для того, чтобы обеспечить общую сеть (для него создаётся network namespace в linux — то есть все контейнеры PODа должны располагаться на одной ноде).
[[Kubernetes#^885a61|К списку вопросов]]
**Каким образом мы можем управлять размещением PODов на конкретных нодах кластера k8s?**
	Для этого существует несколько возможностей.
	- NodeSelector/node affinity — механизм, позволяющий запускать PODы на нодах с определённым набором меток (labels). Это может быть полезно, если, например, PODы требуют определённого оборудования — скажем, у нас есть пул нод с GPU для нужд машинного обучения.
	- Tains/tolerations — механизм, позволяющий запрещать запуск на ноде PODов (taint — описывается на ноде), которые не имеют разрешения (toleration — описывается на POD’е). Это может быть полезно, если у нас в кластере несколько окружений — мы можем выделить ноды под production и при помощи taint запретить запускать там PODы тестовых окружений.
	- Pod affinity/antiAffinity — механизм, позволяющий группировать PODы разных приложений на общих нодах (если, например, им важен быстрый сетевой доступ) или, наоборот — заставлять их запускаться на разных нодах (например, чтобы распределить PODы одного приложения по нодам кластера для повышения отказоустойчивости в случае сбоя на ноде).
[[Kubernetes#^885a61|К списку вопросов]]
**Что такое Pod Disruption Budget (PDB)?**
	Это функционал k8s, позволяющий держать запущенными минимально необходимое количество PODов приложения. То есть при возникновении события вроде evict’а PODов с ноды, drain'а ноды, удаления PODов и прочего k8s не удалит PODы, если общее количество PODов приложения ниже PDB.
[[Kubernetes#^885a61|К списку вопросов]]
**Что такое POD eviction?**
	Это механизм, позволяющий освободить ноду от лишних PODов. Бывают evict’ы по ресурсам (когда на ноде не хватает памяти, места на диске или количества PID для процессов) и посредством вызова API — когда мы запускаем kubectl drain node.
[[Kubernetes#^885a61|К списку вопросов]]
**Каким образом мы можем вывести ноду из работы для обслуживания?**
	Мы можем запретить запуск PODов на ноде с помощью kubectl cordon и удалить PODы с ноды при помощи kubectl drain.
[[Kubernetes#^885a61|К списку вопросов]]
**Что такое priority classes?**
	Это механизм k8s, позволяющий указать важность PODов для наших процессов. Например, если в одном кластере k8s у нас продуктовый и тестовые окружения, мы можем повысить priority class для PODов продуктового, и если, например, возникнет недостаток ресурсов на ноде, первыми для evict’а будут выбраны PODы тестовых окружений.
[[Kubernetes#^885a61|К списку вопросов]]
**Что такое Kubernetes probes?**
	Это проверки, которые осуществляются в течение жизненного цикла PODа. Они описываются для каждого контейнера PODа. Существуют три вида проверок.
	- Startup probe — запускается сразу после старта PODа и применяется для приложений, которые имеют длительную процедуру инициализации. Пока она не завершена, другие пробы не запускаются.
	- Readiness probe — проверка готовности PODа обрабатывать трафик (POD не добавляется в маршрутизацию трафика в service, если эта проверка не пройдена).
	- Liveness probe — проверяет, функционирует ли приложение (в случае, если проверка не завершилась успехом, процесс в контейнере PODа перезапускается).
	Readiness и liveness — независимые и запускаются после прохождения startup probe.
	Существуют exec-, http-, tcp- и gprc-пробы. Проверки осуществляются сервисом kubelet на ноде, где запущен целевой POD.
[[Kubernetes#^885a61|К списку вопросов]]
**Какие существуют хорошие практики для создания проб?**
	Пробы должны проверять функционал приложения, задействованный в обработке запросов пользователя. Например, если в приложении есть панель администратора и веб-сайт, то проверять нужно ответ от сайта, причём не какой-то синтетический location, отдающий простой код ответа, но запуск простой функции, которая должна использовать механизмы приложения, близкие к обработке реальных пользовательских запросов.
	Пробы — это дополнительная нагрузка на инфраструктуру, поэтому они не должны осуществлять тяжёлые, ресурсоёмкие запросы к приложению, равно как и не должны запускаться слишком часто. По возможности пробы также не должны проверять функционал, зависящий от внешних сервисов, — иначе можно получить каскадный сбой. Нужно быть очень осторожным с liveness-пробами, — они перезапускают процесс в контейнере и могут вызвать дополнительные проблемы, когда, например, на приложение пришла высокая нагрузка, оно занято обработкой пользовательских запросов и не может ответить на liveness-пробу (лучше сделать выделенный пул воркеров на прохождение liveness-пробы, если проверяемый сервис это позволяет). Лучше всего создавать сквозные проверки для readiness-пробы — например, если в PODе связка nginx + php-fpm, проверять можно только location nginx, который проксирует php-fpm (одним запросом проверяются оба сервиса).
[[Kubernetes#^885a61|К списку вопросов]]
**Что такое пространство имен (namespaces)? Почему не стоит использовать одно namespace для всех приложений?**
	Пространства имен позволяют разделять кластер на виртуальные кластеры, в которых можно объединять приложения в группы по нужному принципу. При этом эти группы будут изолированы друг от друга. Благодаря этому можно, например, создать приложение с одинаковым именем в двух разных пространствах.  
	Если использовать только одно пространство имен, которое было по умолчанию при запуске кластера, то со временем будет сложно ориентироваться во всех запущенных там приложениях. Группировка приложений в разных пространствах имен упростит работу: например, можно в одном пространстве разместить приложение мониторинга, в другом — приложения, связанные с ИБ.  
	Другой сценарий, когда пригодится нескольких пространств имен, — это работа нескольких команд с одним кластером.
[[Kubernetes#^885a61|К списку вопросов]] ^9d023b
**Какую функцию выполняет ReplicaSet?**
	Задача ReplicaSet (RS) — поддерживать работу определенного количества экземпляров подов в кластере Kubernetes. Это базовый строительный блок Kubernetes, который используется для запуска Stateless-приложения. RS часто используется для обеспечения доступности приложения. Если какие-то из подов покрашатся, то Kubernetes с помощью RS автоматически запускает новые экземпляры подов, чтобы заменить вышедшие из строя. Без RS пришлось бы их запускать вручную. Тем самым RS помогает сохранить приложение доступным для пользователей.
[[Kubernetes#^885a61|К списку вопросов]] ^d96056
**Что такое Deployment?**
	Deployment, по сравнению с ReplicaSet, — это абстракция более высокого уровня. Если ReplicaSet отвечает за то, чтобы поды были запущены и доступны, то Deployment помогает делать декларативные апдейты подов, используя ReplicaSet.  
	Когда для группы контейнеров нужно обновить версии или откатиться к предыдущей, мы используем Deployment.
[[Kubernetes#^885a61|К списку вопросов]] ^3ff4f8
**За что отвечает StatefulSet?**
	StatefulSet управляет развертыванием и масштабированием группы подов, но при этом он дает возможность сохранять состояние и характеристики подов.  
	Например, если нужно, чтобы поды запускались в определенном порядке, на тех же нодах, чтобы при каждом запуске у каждого было хранилище (PVC) или какие-то специальные сетевые идентификаторы, используют StatefulSet.  
	Обычно он используется для запуска подов с очередями сообщений, брокеров и БД.
[[Kubernetes#^885a61|К списку вопросов]] ^32615f
**Какая роль у контроллера DaemonSet?**
	DaemonSet используется в Kubernetes, когда нужно запустить один или несколько подов на всех рабочих узлах кластера. То есть при запуске новых нод вам не потребуется вручную запускать поды, которые должны там быть для каких-то служебных задач. Например, с помощью него можно запустить поды с Prometheus Node Exporter для мониторинга, collectd или поды с fluentd or logstash для логирования узлов.
[[Kubernetes#^885a61|К списку вопросов]] ^883294
**Как в Kubernetes устроена работа с хранилищами?**
	У Kubernetes есть volumes, например, нативный emtyDir. Часть из них stateless, то есть они живут, пока жив под. Судьба у данных, которые туда попадают, аналогичная.  
	Для statefull-приложений используются постоянные хранилища, Persistent Volumes (PV). Persistent Volumes (PV) — это единицы хранения, которые были выделены кластеру Kubernetes его администратором. Это могут быть локальные диски, СХД, внешние дисковые полки. Они никак не зависят от жизненного цикла подов.  
	Persistent Volume Claim (PVC) — это запрос на выделение PV определенных характеристик: типа хранилища, объема, типа доступа (чтение и/или запись). Для описания подробных характеристик доступных PV используются Storage Classes.  
	В динамике это все выглядит следующим образом: под отправляет PVC, а PVC уже обращается к PV и передает ее поду.
	![[Pasted image 20241104213110.png]]
[[Kubernetes#^885a61|К списку вопросов]] ^ccbb49
**Как в Kubernetes сделать приложение доступным извне по сети интернет?**
	Для этого нужно будет настроить сервисы (Services).  
	**ClusterIP** — сущность, которая позволяет маршрутизировать запросы к подам на статичный IP-адрес. Благодаря ClusterIP у нас будет неизменная точка входа, даже если сами поды будут крашиться и восстанавливаться снова.    
	**NodePort** делает сервис доступным извне через статический порт на каждом узле кластера. Любой трафик, отправленный на этот порт, будет перенаправлен на сервис. При этом ClusterIP создается автоматически.  
	**LoadBalancer** публикует сервис вовне и заводит трафик от балансировщика облачного провайдера внутрь кластера.  
	**External name** сопоставляет сервис с DNS-именем (например, example.com). Он создает CNAME-запись, которая соединяет DNS-имя с определенным именем внутри кластера. Выступает как прокси, которое позволяет пользователю перенаправлять запросы сервису, находящемуся внутри или за пределами кластера.
[[Kubernetes#^885a61|К списку вопросов]] ^42da4e
**Что такое ingress и зачем он нужен?**
	Ingress позволяет настраивать правила маршрутизации для трафика от внешних источников до сервисов внутри кластера.  
	В Ingress описываются сами правила маршрутизации к сетевым сервисам, а  
	контроллер Ingress отвечает за их выполнение. Контроллер не поставляется в Kubernetes, но можно использовать одно из сторонних решений, предварительно изучив их возможности и особенности.
[[Kubernetes#^885a61|К списку вопросов]]
**Если нам всё равно нужно описывать Kubernetes service для публикации ingress, то зачем нам ingress?**
	Преимущество ingress-контроллера в том, что, опубликовав его единожды, мы получим возможность доставлять через него трафик всем нашим приложениям внутри кластера k8s, которые работают по HTTP на основе маршрутизации по URL/locations, HTTP headers и cookie. А также если появится такая необходимость, мы сможем использовать несколько ingress-контроллеров в кластере, разделяя их по ingress class.
[[Kubernetes#^885a61|К списку вопросов]] 
**Допустим, у нас postgresql в кластере k8s, и разработчики просят к ней доступ. Каким образом мы можем решить этот вопрос?**
	Прежде всего, мы можем развернуть в кластере веб-основанный тулинг для работы с базой, например pgadmin, и опубликовать его через ingress для разработчиков.
	Есть также вариант с использованием какого-нибудь инструмента для доступа разработчика к кластеру (например, Kubernetes dashboard или LENS) с возможностью сделать exec в POD и доступа к базе через утилиту командной строки.
	Если разработчикам всё-таки нужен прямой сетевой доступ к базе (например, для использования своего любимого инструмента работы с БД), мы можем завести аккаунт для разработчиков в кластере и использовать kubectl proxy для публикации порта базы на localhost машины разработчика. Либо поднять в кластере сервер vpn.
	На худой конец, есть возможность опубликовать базу через Kubernetes service или ingress, но в данном случае нам нужно позаботиться о защите соединения с БД (пользователи, доступы) и протокола (включить шифрование).
[[Kubernetes#^885a61|К списку вопросов]] 
**Расскажите, как вы будете запускать приложение в Kubernetes, если из инструментов у вас только kubectl?**
	В общем виде последовательность действий выглядит следующим образом:  
	1. Для запуска в Kubernetes приложение должно быть упаковано в контейнер, поэтому первым шагом будет поместить приложение в контейнер.
	2. Затем нужно запустить контейнер в виде набора реплик (подов). Для этого используем Deployment.
	3. Для того чтобы приложение было доступно в интернете и к нему можно было подключиться, нужно настроить сервис LoadBalancer, который позволит присвоить публичный IP-адрес и подключиться к кластеру из внешней сети.
	4. Чтобы маршрутизировать пришедший через балансировщик трафик до приложения, в кластере должен быть создан Ingress, описывающий правила маршрутизации, и запущен Ingress-контроллер.
	Проделать все это можно через kubectl, командную строку по сути. Это императивный и самый простой способ, когда мы как бы говорим Kubernetes «сделай это и это».    
	Второй способ, который применяется уже в промышленной эксплуатации, — это управление через декларативные манифесты, в которых мы описываем желаемое состояние, а Kubernetes уже сам решает, какие действия для этого нужно сделать. Затем эти манифесты отправляем в Kubernetes c помощью команды kubectl apply.
[[Kubernetes#^885a61|К списку вопросов]] ^320f06
**Приложение перестало работать — как понять, что случилось?**
	Причин, по которым приложение не работает в кластере Kubernetes, много.  
	Вот самые распространенные:  
	- под отсутствует;
	- под не запускается (статус Pending);
	- под запускается, но падает с ошибкой (статус CrashLoopBackOff);
	- под работает (статус Runnung), но недоступен по сети.
	Ниже кратко рассмотрим алгоритмы, позволяющие понять, что же все-таки случилось.  
	1. Для начала нужно убедиться, что манифест выполнился и под действительно зарегистрирован в кластере. Если подов и деплоймента не находится, проверьте манифесты.
	2. Если поды находятся в статусе Pending, значит Scheduler не может найти подходящую ноду для запуска пода. На это тоже может быть много причин: недостаточно ресурсов в кластере, несовпадение taints/tolerances, невозможность скачать образ и многое другое. Найти причину помогут события, связанные с подом, однако некоторые проблемы (например, отказ Scheduler) не попадут в этот список. Также проверьте статус нод в кластере и селекторы, указанные в манифесте.
	3. Если под был назначен ноде, но при запуске произошла ошибка, под будет иметь статус CrashLoopBackOff и кластер будет предпринимать попытки запустить его повторно. Обычно это происходит в случае ошибки в самом приложении внутри контейнера, а найти причину обычно помогают логи (если приложение их пишет, конечно).
	4. Следующая ситуация — поды работают (статус Running), однако не доступны по сети из других подов. Для начала нужно проверить, создан ли Service с соответствующим селектором. Также необходимо проверить, что они находятся в одном namespace. 
	Если сервисы существуют, но доступа нет, причина может быть в правилах NetworkPolicy, ограничивающих доступ сервисов друг к другу. Проверьте эти ограничения.  
	Если сервис должен быть доступен извне кластера (из интернета или приватной сети), необходимо проверить наличие Ingress-правила, описывающего маршрутизацию L7-трафика на выбранный сервис. Также стоит проверить состояние Ingress Controller: если он не работает, правила не будут исполняться.  
	Кроме того, для прохождения запроса внутрь кластера должна существовать точка входа, через которую запрос попадает на Ingress Controller. Такой точкой служит Service NodePort для кластеров on-premise инфраструктуры или LoadBalancer для кластеров в облаке.  
	Каждый из этих шагов можно выполнить через набор команд kubectl или через графический клиент, например, Lens.
[[Kubernetes#^885a61|К списку вопросов]]

[[Kubernetes#^086721|К содержанию]]
